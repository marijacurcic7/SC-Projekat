{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# prikaz vecih slika \n",
    "matplotlib.rcParams['figure.figsize'] = 16,12\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, Conv3D, BatchNormalization, MaxPool2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spectogram(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name,res_type=\"kaiser_fast\" ,sr=22050)\n",
    "        a, index = librosa.effects.trim(audio, top_db=30, frame_length=2048, hop_length=512)\n",
    "        y_out = a[:44100]\n",
    "        spectrogram = librosa.feature.melspectrogram(y=y_out, sr=sample_rate, n_fft=2048, hop_length=1024)\n",
    "        spec_shape = spectrogram.shape\n",
    "        if(spec_shape[1] < 44):\n",
    "            print(spec_shape)\n",
    "            print(file_name)\n",
    "        spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "        return spectrogram\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None\n",
    "    \n",
    "    return mfccscaled    \n",
    "\n",
    "def my_rgb2gray(img_rgb):\n",
    "    img_gray = np.ndarray((img_rgb.shape[0], img_rgb.shape[1]))  # zauzimanje memorije za sliku (nema trece dimenzije)\n",
    "    img_gray = 0.21*img_rgb[:, :] + 0.72*img_rgb[:, :] #+ 0.07*img_rgb[:, :, 2]\n",
    "    return img_gray\n",
    "\n",
    "def normalize_gray(array):\n",
    "    return (array - array.min())/(array.max() - array.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"dataset/\"\n",
    "folder_list = [\"Accordion\",\"Clarinet_Bb\",\"Contrabass\",\"Horn\",\"Viola\",\"Violin\",\"Violoncello\"]\n",
    "features = []\n",
    "onlyfiles = []\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "for folder_inst in folder_list:\n",
    "    onlyfiles = onlyfiles + [f for f in listdir(\"dataset/\" + folder_inst) if isfile(join(\"dataset/\" + folder_inst + \"/\", f))]\n",
    "    \n",
    "\n",
    "\n",
    "for file in onlyfiles: \n",
    "    dodatak = ''\n",
    "    if (file.split(\"-\")[0] == \"Acc\"):\n",
    "        dodatak = \"Accordion\"\n",
    "    elif (file.split(\"-\")[0] == \"ClBb\"):\n",
    "        dodatak = \"Clarinet_Bb\"\n",
    "    elif (file.split(\"-\")[0] == \"Cb\"):\n",
    "        dodatak = \"Contrabass\"\n",
    "    elif (file.split(\"-\")[0] == \"Hn\"):\n",
    "        dodatak = \"Horn\"\n",
    "    elif (file.split(\"-\")[0] == \"Va\"):\n",
    "        dodatak = \"Viola\"\n",
    "    elif (file.split(\"-\")[0] == \"Vn\"):\n",
    "        dodatak = \"Violin\"\n",
    "    elif (file.split(\"-\")[0] == \"Vc\"):\n",
    "        dodatak = \"Violoncello\"\n",
    "    \n",
    "    file_name = folder_path + dodatak + \"/\" + file\n",
    "    a = file.split(\"-\")\n",
    "    instrument = a[0]\n",
    "    pitch = a[2]\n",
    "    if(len(pitch) == 3):\n",
    "        pitch = pitch[:2]\n",
    "    else:\n",
    "        pitch = pitch[:1]\n",
    "    data = extract_spectogram(file_name)\n",
    "    features.append([file_name, data, instrument, pitch])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>feature</th>\n",
       "      <th>instrument</th>\n",
       "      <th>pitch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset/Accordion/Acc-ord-A#3-ff-alt1-N.wav</td>\n",
       "      <td>[[0.29073387, 0.33191147, 0.2776536, 0.2996274...</td>\n",
       "      <td>Acc</td>\n",
       "      <td>A#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset/Accordion/Acc-ord-A#3-ff-alt2-N.wav</td>\n",
       "      <td>[[0.3070023, 0.3617015, 0.27213687, 0.36119562...</td>\n",
       "      <td>Acc</td>\n",
       "      <td>A#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset/Accordion/Acc-ord-A#3-ff-N-N.wav</td>\n",
       "      <td>[[0.47353348, 0.42426324, 0.3613015, 0.4068834...</td>\n",
       "      <td>Acc</td>\n",
       "      <td>A#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset/Accordion/Acc-ord-A#3-mf-alt1-N.wav</td>\n",
       "      <td>[[0.42782307, 0.46233648, 0.38736117, 0.385382...</td>\n",
       "      <td>Acc</td>\n",
       "      <td>A#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset/Accordion/Acc-ord-A#3-mf-alt2-N.wav</td>\n",
       "      <td>[[0.6518973, 0.62134737, 0.5658642, 0.48233718...</td>\n",
       "      <td>Acc</td>\n",
       "      <td>A#</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          file  \\\n",
       "0  dataset/Accordion/Acc-ord-A#3-ff-alt1-N.wav   \n",
       "1  dataset/Accordion/Acc-ord-A#3-ff-alt2-N.wav   \n",
       "2     dataset/Accordion/Acc-ord-A#3-ff-N-N.wav   \n",
       "3  dataset/Accordion/Acc-ord-A#3-mf-alt1-N.wav   \n",
       "4  dataset/Accordion/Acc-ord-A#3-mf-alt2-N.wav   \n",
       "\n",
       "                                             feature instrument pitch  \n",
       "0  [[0.29073387, 0.33191147, 0.2776536, 0.2996274...        Acc    A#  \n",
       "1  [[0.3070023, 0.3617015, 0.27213687, 0.36119562...        Acc    A#  \n",
       "2  [[0.47353348, 0.42426324, 0.3613015, 0.4068834...        Acc    A#  \n",
       "3  [[0.42782307, 0.46233648, 0.38736117, 0.385382...        Acc    A#  \n",
       "4  [[0.6518973, 0.62134737, 0.5658642, 0.48233718...        Acc    A#  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#menjanje boje slike\n",
    "features_gray = []\n",
    "for list in features:\n",
    "    imggray = my_rgb2gray(list[1])\n",
    "    features_gray.append([list[0],normalize_gray(imggray), list[2], list[3]])\n",
    "    \n",
    "features_df = pd.DataFrame(features_gray, columns=[\"file\", \"feature\", \"instrument\", \"pitch\"])\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1852"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ = 0\n",
    "a = 0 \n",
    "b = 0 \n",
    "c_ = 0\n",
    "c = 0\n",
    "d_ = 0\n",
    "d = 0\n",
    "e = 0\n",
    "f_ = 0\n",
    "f = 0\n",
    "g_ = 0\n",
    "g = 0\n",
    "for x in features_gray:\n",
    "    if(x[3] == \"A#\"):\n",
    "        a_+=1\n",
    "    if(x[3] == \"A\"):\n",
    "        a+=1\n",
    "    if(x[3] == \"B\"):\n",
    "        b+=1\n",
    "    if(x[3] == \"C#\"):\n",
    "        c_+=1\n",
    "    if(x[3] == \"C\"):\n",
    "        c+=1\n",
    "    if(x[3] == \"D#\"):\n",
    "        d_+=1\n",
    "    if(x[3] == \"D\"):\n",
    "        d+=1\n",
    "    if(x[3] == \"E\"):\n",
    "        e+=1\n",
    "    if(x[3] == \"F\"):\n",
    "        f+=1\n",
    "    if(x[3] == \"F#\"):\n",
    "        f_+=1\n",
    "    if(x[3] == \"G\"):\n",
    "        g+=1\n",
    "    if(x[3] == \"G#\"):\n",
    "        g_+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:  149\n",
      "A#:  150\n",
      "B:  154\n",
      "C:  165\n",
      "C#:  145\n",
      "D:  160\n",
      "D#:  158\n",
      "E:  163\n",
      "F:  151\n",
      "F#:  142\n",
      "G:  161\n",
      "G#:  154\n"
     ]
    }
   ],
   "source": [
    "print(\"A: \", a_)\n",
    "print(\"A#: \", a)\n",
    "print(\"B: \", b)\n",
    "print(\"C: \", c)\n",
    "print(\"C#: \", c_)\n",
    "print(\"D: \", d)\n",
    "print(\"D#: \", d_)\n",
    "print(\"E: \", e)\n",
    "print(\"F: \", f)\n",
    "print(\"F#: \", f_)\n",
    "print(\"G: \", g)\n",
    "print(\"G#: \", g_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1481, 128, 44, 1)\n",
      "(185, 128, 44, 1)\n",
      "(186, 128, 44, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(features_df.feature.tolist())\n",
    "yinst = np.array(features_df.pitch.tolist())\n",
    "\n",
    "leinst = LabelEncoder()\n",
    "yyinst = leinst.fit_transform(yinst)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yyinst, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "x_test, x_validation, y_test, y_validation = train_test_split(x_test, y_test, test_size=0.5, shuffle=True, random_state=42)\n",
    "\n",
    "x_train = x_train.reshape(len(x_train),128,44,1)\n",
    "x_test = x_test.reshape(len(x_test),128,44,1)\n",
    "x_validation = x_validation.reshape(len(x_validation),128,44,1)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(x_validation.shape)\n",
    "\n",
    "\n",
    "num_classes = len(leinst.classes_)\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "y_validation = to_categorical(y_validation, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 126, 42, 32)       320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 63, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 63, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 61, 19, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 30, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 30, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 17280)             0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 12)                207372    \n",
      "=================================================================\n",
      "Total params: 226,188\n",
      "Trainable params: 226,188\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(128,44,1)))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Dropout(0.25))\n",
    "model1.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Dropout(0.25))\n",
    "model1.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model1.add(Dense(num_classes, activation='softmax'))\n",
    "#Compile\n",
    "model1.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 126, 42, 16)       160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 21, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 21, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 61, 19, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 9, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 9, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8640)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1106048   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 1,112,396\n",
      "Trainable params: 1,112,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(128,44,1)))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(128,44,1)))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(num_classes, activation='softmax'))\n",
    "model2.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_31 (Conv2D)           (None, 126, 42, 32)       320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 63, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 63, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 42336)             0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 128)               5419136   \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 5,421,004\n",
      "Trainable params: 5,421,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(128,44,1 )))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(Dropout(0.25))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(128, activation='relu'))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(num_classes, activation='softmax'))\n",
    "#Compile\n",
    "model3.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1481 samples, validate on 186 samples\n",
      "Epoch 1/100\n",
      "1481/1481 [==============================] - 3s 2ms/step - loss: 2.0641 - accuracy: 0.3592 - val_loss: 1.0718 - val_accuracy: 0.8172\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.07182, saving model to best_weights.hdf5\n",
      "Epoch 2/100\n",
      "1481/1481 [==============================] - 3s 2ms/step - loss: 0.7185 - accuracy: 0.7927 - val_loss: 0.3478 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.07182 to 0.34784, saving model to best_weights.hdf5\n",
      "Epoch 3/100\n",
      "1481/1481 [==============================] - 3s 2ms/step - loss: 0.4150 - accuracy: 0.8764 - val_loss: 0.2291 - val_accuracy: 0.9355\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.34784 to 0.22908, saving model to best_weights.hdf5\n",
      "Epoch 4/100\n",
      "1481/1481 [==============================] - 3s 2ms/step - loss: 0.3052 - accuracy: 0.9055 - val_loss: 0.1625 - val_accuracy: 0.9462\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.22908 to 0.16246, saving model to best_weights.hdf5\n",
      "Epoch 5/100\n",
      "1481/1481 [==============================] - 3s 2ms/step - loss: 0.2185 - accuracy: 0.9365 - val_loss: 0.1154 - val_accuracy: 0.9785\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.16246 to 0.11538, saving model to best_weights.hdf5\n",
      "Epoch 6/100\n",
      "1481/1481 [==============================] - 4s 3ms/step - loss: 0.1650 - accuracy: 0.9521 - val_loss: 0.0876 - val_accuracy: 0.9839\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.11538 to 0.08755, saving model to best_weights.hdf5\n",
      "Epoch 7/100\n",
      "1481/1481 [==============================] - 4s 3ms/step - loss: 0.1434 - accuracy: 0.9588 - val_loss: 0.0749 - val_accuracy: 0.9839\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.08755 to 0.07490, saving model to best_weights.hdf5\n",
      "Epoch 8/100\n",
      "1481/1481 [==============================] - 3s 2ms/step - loss: 0.1298 - accuracy: 0.9602 - val_loss: 0.0674 - val_accuracy: 0.9839\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.07490 to 0.06740, saving model to best_weights.hdf5\n",
      "Epoch 9/100\n",
      "1481/1481 [==============================] - 4s 3ms/step - loss: 0.0997 - accuracy: 0.9710 - val_loss: 0.0543 - val_accuracy: 0.9839\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.06740 to 0.05425, saving model to best_weights.hdf5\n",
      "Epoch 10/100\n",
      "1481/1481 [==============================] - 4s 2ms/step - loss: 0.0890 - accuracy: 0.9737 - val_loss: 0.0428 - val_accuracy: 0.9892\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.05425 to 0.04277, saving model to best_weights.hdf5\n",
      "Epoch 11/100\n",
      "1481/1481 [==============================] - 4s 3ms/step - loss: 0.0796 - accuracy: 0.9757 - val_loss: 0.0400 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.04277 to 0.03996, saving model to best_weights.hdf5\n",
      "Epoch 12/100\n",
      "1481/1481 [==============================] - 4s 2ms/step - loss: 0.0624 - accuracy: 0.9845 - val_loss: 0.0406 - val_accuracy: 0.9892\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.03996\n",
      "Epoch 13/100\n",
      "1481/1481 [==============================] - 4s 3ms/step - loss: 0.0551 - accuracy: 0.9858 - val_loss: 0.0380 - val_accuracy: 0.9892\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.03996 to 0.03797, saving model to best_weights.hdf5\n",
      "Epoch 14/100\n",
      "1481/1481 [==============================] - 4s 2ms/step - loss: 0.0575 - accuracy: 0.9858 - val_loss: 0.0300 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.03797 to 0.02995, saving model to best_weights.hdf5\n",
      "Epoch 15/100\n",
      "1481/1481 [==============================] - 3s 2ms/step - loss: 0.0564 - accuracy: 0.9811 - val_loss: 0.0278 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.02995 to 0.02780, saving model to best_weights.hdf5\n",
      "Epoch 16/100\n",
      "1481/1481 [==============================] - 3s 2ms/step - loss: 0.0445 - accuracy: 0.9899 - val_loss: 0.0262 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.02780 to 0.02617, saving model to best_weights.hdf5\n",
      "Epoch 17/100\n",
      "1481/1481 [==============================] - 3s 2ms/step - loss: 0.0562 - accuracy: 0.9818 - val_loss: 0.0280 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.02617\n",
      "Epoch 18/100\n",
      "1481/1481 [==============================] - 4s 2ms/step - loss: 0.0362 - accuracy: 0.9926 - val_loss: 0.0285 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.02617\n",
      "Epoch 19/100\n",
      "1481/1481 [==============================] - 4s 2ms/step - loss: 0.0276 - accuracy: 0.9919 - val_loss: 0.0190 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.02617 to 0.01903, saving model to best_weights.hdf5\n",
      "Epoch 20/100\n",
      "1481/1481 [==============================] - 3s 2ms/step - loss: 0.0427 - accuracy: 0.9878 - val_loss: 0.0241 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01903\n",
      "Epoch 21/100\n",
      "1481/1481 [==============================] - 4s 2ms/step - loss: 0.0380 - accuracy: 0.9878 - val_loss: 0.0289 - val_accuracy: 0.9892\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01903\n",
      "Epoch 22/100\n",
      "1481/1481 [==============================] - 4s 2ms/step - loss: 0.0385 - accuracy: 0.9905 - val_loss: 0.0193 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01903\n",
      "Epoch 23/100\n",
      "1481/1481 [==============================] - 3s 2ms/step - loss: 0.0269 - accuracy: 0.9926 - val_loss: 0.0227 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01903\n",
      "Epoch 24/100\n",
      "1481/1481 [==============================] - 4s 2ms/step - loss: 0.0285 - accuracy: 0.9939 - val_loss: 0.0277 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01903\n",
      "Epoch 25/100\n",
      "1344/1481 [==========================>...] - ETA: 0s - loss: 0.0343 - accuracy: 0.9874"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"best_weights.hdf5\", verbose=1, save_best_only=True)\n",
    "\n",
    "start = datetime.now()\n",
    "model2.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs, validation_data=(x_validation, y_validation), \n",
    "           callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1481/1481 [==============================] - 1s 454us/step\n",
      "Training Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "train_score = model2.evaluate(x_train, y_train, verbose=1)\n",
    "print(\"Training Accuracy: \", train_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 499us/step\n",
      "Test Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "test_score = model2.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Test Accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
